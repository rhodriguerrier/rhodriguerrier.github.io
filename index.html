<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Rhodri Guerrier</title>

    <meta name="author" content="Rhodri Guerrier">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Rhodri Guerrier
                </p>
                <p>
		I am a computer vision PhD student at the University of Bristol, supervised by Professor Dima Damen.
		My research focuses on point tracking and 3D reconstruction, with an emphasis on applying this to egocentric video.
                </p>
                <p style="text-align:center">
                  <a href="mailto:rhodri.guerrier@bristol.ac.uk">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=sBkSGDcAAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/rhodriguerrier/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/rhodri_profile_pic.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/rhodri_profile_pic.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pointst3r_image'>
					  <img src='images/pointst3r_img.png' width=100%>
					</div>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://rhodriguerrier.github.io/PointSt3R">
			<span class="papertitle">PointSt3R: Point Tracking through 3D Grounded Correspondence
</span>
        </a>
        <br>
		<strong>Rhodri Guerrier</strong>, 
		<a href="https://adamharley.com/">Adam Harley</a>,
		<a href="https://dimadamen.github.io/">Dima Damen</a>
	<br>
        <em>arXiv</em>, 2025
        <br>
        <a href="https://rhodriguerrier.gitlab.io/PointSt3R/">project page</a>
        /
        <a href="REPLACE WITH ARXIV LINK WHEN READY">arXiv</a>
        <p></p>
        <p>
		Simple fine-tuning of MASt3R foundation model produces competitive point tracking results to state-of-the-art.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='hd_epic_image'>
                                          <img src='images/hd_epic_logo_black.png' width=100%>
                                        </div>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://hd-epic.github.io/">
                        <span class="papertitle">HD-EPIC: A Highly-Detailed Egocentric Video Dataset
</span>
        </a>
        <br>
		<a href="https://tobyperrett.github.io/">Toby Perrett</a>,
		<a href="https://ahmaddarkhalil.github.io/">Ahmad Dar Khalil</a>,
		<a href="https://sinhasaptarshi.github.io/">Saptarshi Sinha</a>,
		<a href="https://omar-emara.github.io/">Omar Emara</a>,
		<a href="https://sjpollard.github.io/">Sam Pollard</a>,
		<a href="https://krantiparida.github.io/">Kranti Kumar Parida</a>,
		<a>Kaiting Liu</a>,
		<a href="https://prajwalgatti.github.io/">Prajwal Gatti</a>,
		<a href="https://sid2697.github.io/">Siddhant Bansal</a>,
		<a href="https://keflanagan.github.io/">Kevin Flanagan</a>,
		<a href="https://jacobchalk.github.io/">Jacob Chalk</a>,
		<a href="https://zhifanzhu.github.io/">Zhifan Zhu</a>,
		<strong>Rhodri Guerrier</strong>,
		<a>Fahd Abdelazim</a>,
		<a href="https://binzhubz.github.io/">Bin Zhu</a>,
		<a href="https://www.davidemoltisanti.com/research">Davide Moltisanti</a>,
		<a href="https://mwray.github.io/">Michael Wray</a>,
		<a href="https://hazeldoughty.github.io/">Hazel Doughty</a>,
		<a href="https://dimadamen.github.io/">Dima Damen</a>
        <br>
        <em>CVPR</em>, 2025
        <br>
        <a href="https://hd-epic.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2502.04144">arXiv</a>
        <p></p>
        <p>
                A highly detailed kitchen-based egocentric dataset, manually annotated with ground truth labels covering: recipe steps, fine-grained actions, ingredients with nutritional values, moving objects, and audio annotations. All annotations are grounded in 3D through a digital twin of each environment.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='egopoints_image'>
                                          <img src='images/egopoints_img.png' width=100%>
                                        </div>
        </div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ahmaddarkhalil.github.io/EgoPoints/">
                        <span class="papertitle">EgoPoints: Advancing Point Tracking for Egocentric Videos
</span>
        </a>
        <br>
                <a href="https://ahmaddarkhalil.github.io/">Ahmad Dar Khalil</a>,
                <strong>Rhodri Guerrier</strong>,
		<a href="https://adamharley.com/">Adam Harley</a>
                <a href="https://dimadamen.github.io/">Dima Damen</a>
        <br>
        <em>WACV</em>, 2025
        <br>
        <a href="https://ahmaddarkhalil.github.io/EgoPoints/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.04592">arXiv</a>
        <p></p>
        <p>
		A benchmark for point tracking in egocentric visions which highlights the difficulty current models face performing under the scenarios such as motion blur and frequent re-identification.
        </p>
      </td>
    </tr>
  </body>
</html>
